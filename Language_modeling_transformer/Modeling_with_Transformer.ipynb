{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Языковая модель с трансформером на основе \"Войны и мира\""
      ],
      "metadata": {
        "id": "lqrys80561dO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Подготовка среды и вспомогательные функции"
      ],
      "metadata": {
        "id": "DK9SVlA066H9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XwW8ASc6O3L",
        "outputId": "07fd7ded-254d-4935-a204-9bd6bf1a3599"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting youtokentome\n",
            "  Downloading youtokentome-1.0.6.tar.gz (86 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/86.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/86.7 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: Click>=7.0 in /usr/local/lib/python3.11/dist-packages (from youtokentome) (8.2.1)\n",
            "Building wheels for collected packages: youtokentome\n",
            "  Building wheel for youtokentome (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for youtokentome: filename=youtokentome-1.0.6-cp311-cp311-linux_x86_64.whl size=1968568 sha256=337b981303aee16b55b0e9e833d103e6674c75e41ff00bb702f652d955fc5c1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/7c/e2/f8069c8e5ebb9f9a26963e906ffcae4977c6322af5ecaf25fc\n",
            "Successfully built youtokentome\n",
            "Installing collected packages: youtokentome\n",
            "Successfully installed youtokentome-1.0.6\n"
          ]
        }
      ],
      "source": [
        "!pip install youtokentome"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Настройка среды и импорт библиотек\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import youtokentome as yttm\n",
        "import os\n",
        "import math"
      ],
      "metadata": {
        "id": "PFBM0hoG6Wzo"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Вспомогательные функции\n",
        "\n",
        "def init_random_seed(seed=42):\n",
        "    \"\"\"Инициализация случайных чисел для воспроизводимости\"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "def get_params_number(model):\n",
        "    \"\"\"Подсчет количества параметров модели\"\"\"\n",
        "    return sum(p.numel() for p in model.parameters())\n",
        "\n",
        "def save_texts_to_file(texts, filename):\n",
        "    \"\"\"Сохранение списка текстов в файл\"\"\"\n",
        "    with open(filename, 'w', encoding='utf-8') as f:\n",
        "        for text in texts:\n",
        "            f.write(text + '\\n')\n",
        "\n",
        "def load_war_and_piece_chunks(filepath):\n",
        "    \"\"\"Загрузка и разбиение текста на фрагменты\"\"\"\n",
        "    with open(filepath, 'r', encoding='utf-8') as f:\n",
        "        text = f.read()\n",
        "\n",
        "    # Улучшенное разбиение на предложения\n",
        "    sentences = []\n",
        "    current = []\n",
        "\n",
        "    for char in text:\n",
        "        current.append(char)\n",
        "        if char in '.!?…\"':\n",
        "            if len(current) > 50:  # Минимальная длина предложения\n",
        "                sentences.append(''.join(current).strip())\n",
        "                current = []\n",
        "\n",
        "    if current:\n",
        "        sentences.append(''.join(current).strip())\n",
        "\n",
        "    return sentences"
      ],
      "metadata": {
        "id": "-aHlDqn66bki"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Загрузка и подготовка данных"
      ],
      "metadata": {
        "id": "xr3s_k417L5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Инициализация случайного seed\n",
        "init_random_seed()"
      ],
      "metadata": {
        "id": "a0IMoP1R6o9x"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка данных\n",
        "all_chunks = load_war_and_piece_chunks('war_and_peace.txt')\n",
        "print(f\"Всего фрагментов: {len(all_chunks)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6_AzIng6pAI",
        "outputId": "80eaa270-03a0-4cec-94e3-95acd8084dac"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Всего фрагментов: 6599\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример текста\n",
        "print(\"Пример фрагмента:\")\n",
        "print(all_chunks[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r_dynNLw6pFW",
        "outputId": "de0788c1-4fad-479b-f13a-3565b4aa1c8c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример фрагмента:\n",
            "Он подошел к Анне\n",
            "Павловне, поцеловал ее руку, подставив ей свою надушенную и сияющую лысину, и\n",
            "покойно уселся на диване.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Перемешивание и разделение на обучающую/тестовую выборки\n",
        "np.random.shuffle(all_chunks)\n",
        "TRAIN_SPLIT = int(len(all_chunks) * 0.7)\n",
        "train_texts = all_chunks[:TRAIN_SPLIT]\n",
        "test_texts = all_chunks[TRAIN_SPLIT:]\n",
        "\n",
        "print(f\"Размер обучающей выборки: {len(train_texts)}\")\n",
        "print(f\"Размер тестовой выборки: {len(test_texts)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C0I_4n3V6pHt",
        "outputId": "e4b3b1e9-b671-4ce9-aa77-146c7443c197"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Размер обучающей выборки: 4619\n",
            "Размер тестовой выборки: 1980\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Обучение токенизатора"
      ],
      "metadata": {
        "id": "iwCoScNC7iCb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение BPE-токенизатора\n",
        "BPE_MODEL_FILENAME = 'war_and_peace_bpe.yttm'\n",
        "TRAIN_TEXTS_FILENAME = 'war_and_peace_bpe_train.txt'\n",
        "\n",
        "save_texts_to_file(train_texts, TRAIN_TEXTS_FILENAME)\n",
        "\n",
        "print(\"Обучение BPE-токенизатора...\")\n",
        "yttm.BPE.train(data=TRAIN_TEXTS_FILENAME, vocab_size=5000, model=BPE_MODEL_FILENAME)\n",
        "\n",
        "tokenizer = yttm.BPE(BPE_MODEL_FILENAME)\n",
        "print(\"Пример токенизации:\", tokenizer.encode(train_texts[:1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "axjoXjhY6pKL",
        "outputId": "b77de41f-7257-4e4d-de65-e3c70ead22c5"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Обучение BPE-токенизатора...\n",
            "Пример токенизации: [[2006, 375, 1035, 1846, 423, 16, 679, 1375, 3675, 371, 1957, 199, 485, 4285, 3065, 658, 2052, 653, 2528, 1279, 375, 1035, 1851, 500, 231, 31, 2541, 260, 2627, 220, 228, 35, 1582, 1211, 375, 1035, 1901, 246, 724, 221, 991, 1055, 58]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Преобразование текстов в токены"
      ],
      "metadata": {
        "id": "2Ai0SiIi7opt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Преобразование текстов в токены\n",
        "train_token_ids = tokenizer.encode(train_texts, bos=True, eos=True)\n",
        "test_token_ids = tokenizer.encode(test_texts, bos=True, eos=True)"
      ],
      "metadata": {
        "id": "_mPRPca76pMK"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Визуализация распределения длин фрагментов\n",
        "plt.hist([len(sent) for sent in train_token_ids], bins=30)\n",
        "plt.title('Распределение длин фрагментов в токенах')\n",
        "plt.yscale('log')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "MUbxxu-86pOI",
        "outputId": "7971e400-b999-43c2-ba59-8054c1682d94"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание датасетов\n",
        "CHUNK_LENGTH = 128\n",
        "\n",
        "class LanguageModelDataset(Dataset):\n",
        "    def __init__(self, token_ids, chunk_length=CHUNK_LENGTH):\n",
        "        self.token_ids = token_ids\n",
        "        self.chunk_length = chunk_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        tokens = self.token_ids[idx]\n",
        "        tokens = tokens[:self.chunk_length]\n",
        "        if len(tokens) == 0:  # Пропуск пустых последовательностей\n",
        "            return torch.zeros(self.chunk_length, dtype=torch.long)\n",
        "        padded_tokens = tokens + [0] * (self.chunk_length - len(tokens))\n",
        "        return torch.tensor(padded_tokens)\n",
        "\n",
        "train_dataset = LanguageModelDataset(train_token_ids, chunk_length=CHUNK_LENGTH)\n",
        "test_dataset = LanguageModelDataset(test_token_ids, chunk_length=CHUNK_LENGTH)"
      ],
      "metadata": {
        "id": "ZURDng5D6pQa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Пример из датасета\n",
        "sample = train_dataset[0]\n",
        "print(\"Пример из датасета:\", sample)\n",
        "print(\"Декодированный пример:\", tokenizer.decode([x.item() for x in sample]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rn4tZ-d37yoB",
        "outputId": "6f644b1b-f6e7-41b0-ad2e-c560b0283805"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример из датасета: tensor([   2, 2006,  375, 1035, 1846,  423,   16,  679, 1375, 3675,  371, 1957,\n",
            "         199,  485, 4285, 3065,  658, 2052,  653, 2528, 1279,  375, 1035, 1851,\n",
            "         500,  231,   31, 2541,  260, 2627,  220,  228,   35, 1582, 1211,  375,\n",
            "        1035, 1901,  246,  724,  221,  991, 1055,   58,    3,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0])\n",
            "Декодированный пример: ['<BOS> ] (сноска 51) Я, право, опасаюсь за свои способности перед такой публикой, (сноска 52) Подождите, я возьму мою работу, (сноска 53) О чем вы думаете?<EOS><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD><PAD>']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Определение модели"
      ],
      "metadata": {
        "id": "9VYthBIu8c0o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Вспомогательные функции для модели\n",
        "\n",
        "def make_target_dependency_mask(length):\n",
        "    \"\"\"Создание маски для зависимости между токенами\"\"\"\n",
        "    full_mask = torch.ones(length, length)\n",
        "    ignore_mask = torch.tril(full_mask) < 1\n",
        "    full_mask.masked_fill_(ignore_mask, float('-inf'))\n",
        "    full_mask.masked_fill_(~ignore_mask, 0)\n",
        "    return full_mask\n",
        "\n",
        "def make_positional_encoding(max_length, embedding_size):\n",
        "    \"\"\"Создание позиционных кодировок\"\"\"\n",
        "    time = np.pi * torch.arange(0, max_length).float()\n",
        "    freq_dividers = torch.arange(1, embedding_size // 2 + 1).float()\n",
        "    inputs = time[:, None] / freq_dividers[None, :]\n",
        "\n",
        "    result = torch.zeros(max_length, embedding_size)\n",
        "    result[:, 0::2] = torch.sin(inputs)\n",
        "    result[:, 1::2] = torch.cos(inputs)\n",
        "    return result"
      ],
      "metadata": {
        "id": "zhCidmgw76dI"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Определение модели\n",
        "\n",
        "class BatchFirstTransformerEncoder(nn.Module):\n",
        "    \"\"\"Transformer Encoder с поддержкой batch-first формата\"\"\"\n",
        "    def __init__(self, *args, **kwargs):\n",
        "        super().__init__()\n",
        "        self.impl = nn.TransformerEncoder(*args, **kwargs)\n",
        "        self.initialize_weights()\n",
        "\n",
        "    def forward(self, src, *args, **kwargs):\n",
        "        src = src.transpose(0, 1).contiguous()\n",
        "        result = self.impl(src, *args, **kwargs)\n",
        "        result = result.transpose(0, 1).contiguous()\n",
        "        return result\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        for param in self.impl.parameters():\n",
        "            if param.dim() > 1:\n",
        "                nn.init.xavier_uniform_(param)\n",
        "\n",
        "class LanguageModel(nn.Module):\n",
        "    \"\"\"Языковая модель на основе трансформера\"\"\"\n",
        "    def __init__(self, vocab_size, embedding_size, backbone, emb_dropout=0.0):\n",
        "        super().__init__()\n",
        "        self.embedding_size = embedding_size\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_size, padding_idx=0)\n",
        "        self.emb_dropout = nn.Dropout(emb_dropout)\n",
        "        self.backbone = backbone\n",
        "        self.out = nn.Linear(embedding_size, vocab_size)\n",
        "\n",
        "        # Кэш позиционных кодировок\n",
        "        self.pos_encoding_cache = {}\n",
        "\n",
        "    def forward(self, seed_token_ids):\n",
        "        batch_size, max_in_length = seed_token_ids.shape\n",
        "        seed_padding_mask = (seed_token_ids == 0).to(seed_token_ids.device)\n",
        "\n",
        "        # Создаем маску на правильном устройстве\n",
        "        dependency_mask = make_target_dependency_mask(max_in_length).to(seed_token_ids.device)\n",
        "\n",
        "        seed_embs = self.embeddings(seed_token_ids)\n",
        "\n",
        "        # Создаем позиционные кодировки на нужном устройстве\n",
        "        if max_in_length not in self.pos_encoding_cache:\n",
        "            pos_codes = make_positional_encoding(max_in_length, self.embedding_size)\n",
        "            self.pos_encoding_cache[max_in_length] = pos_codes.to(seed_token_ids.device)\n",
        "\n",
        "        seed_embs = seed_embs + self.pos_encoding_cache[max_in_length][:max_in_length, :]\n",
        "        seed_embs = self.emb_dropout(seed_embs)\n",
        "\n",
        "        target_features = self.backbone(seed_embs, mask=dependency_mask, src_key_padding_mask=seed_padding_mask)\n",
        "        logits = self.out(target_features)\n",
        "        return logits\n",
        "\n",
        "    # Свойство для определения устройства\n",
        "    @property\n",
        "    def device(self):\n",
        "        return next(self.parameters()).device"
      ],
      "metadata": {
        "id": "7fgpoFIP8dwW"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция потерь\n",
        "def lm_cross_entropy(pred, target):\n",
        "    \"\"\"Функция потерь со сдвигом целей на один токен\"\"\"\n",
        "    pred_flat = pred[:, :-1, :].contiguous().view(-1, pred.shape[-1])  # Убираем последний токен предсказаний\n",
        "    target_flat = target[:, 1:].contiguous().view(-1)  # Сдвигаем цели на один токен\n",
        "    return F.cross_entropy(pred_flat, target_flat, ignore_index=0)"
      ],
      "metadata": {
        "id": "WXYMyz0u8ioA"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Создание модели\n",
        "torch_transf_model = LanguageModel(\n",
        "    tokenizer.vocab_size(),\n",
        "    512,\n",
        "    BatchFirstTransformerEncoder(\n",
        "        nn.TransformerEncoderLayer(\n",
        "            d_model=512,\n",
        "            nhead=8,\n",
        "            dim_feedforward=2048,\n",
        "            dropout=0.2,\n",
        "            layer_norm_eps=1e-5,\n",
        "        ),\n",
        "        num_layers=6\n",
        "    ),\n",
        "    emb_dropout=0.2\n",
        ")\n",
        "print(f'Количество параметров: {get_params_number(torch_transf_model):,}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DmFc2vuJ8ltT",
        "outputId": "5c4519c9-5c6e-47f9-efc8-4ad341b2b68b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество параметров: 24,039,304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Обучение модели"
      ],
      "metadata": {
        "id": "61JhI2R88yf-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Функция обучения\n",
        "def train_eval_loop(model, train_dataset, test_dataset, loss_func,\n",
        "                    lr=1e-3, epoch_n=100, batch_size=32, device='cuda',\n",
        "                    early_stopping_patience=10, max_batches_per_epoch_train=100,\n",
        "                    max_batches_per_epoch_val=100, lr_scheduler_ctor=None):\n",
        "    \"\"\"Обучающий цикл с оценкой качества\"\"\"\n",
        "    # optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    optimizer = torch.optim.AdamW(\n",
        "    torch_transf_model.parameters(),\n",
        "    lr=lr,\n",
        "    betas=(0.9, 0.98),\n",
        "    eps=1e-9,\n",
        "    weight_decay=0.01)\n",
        "    scheduler = lr_scheduler_ctor(optimizer) if lr_scheduler_ctor else None\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=batch_size)\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    best_model = None\n",
        "    no_improvement = 0\n",
        "\n",
        "    model = model.to(device)\n",
        "\n",
        "    for epoch in range(epoch_n):\n",
        "        model.train()\n",
        "        train_loss = 0.0\n",
        "\n",
        "        for batch_i, batch in enumerate(train_loader):\n",
        "            if batch_i >= max_batches_per_epoch_train:\n",
        "                break\n",
        "\n",
        "            inputs = batch.to(device)\n",
        "            targets = inputs.clone()\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(inputs)\n",
        "            loss = loss_func(logits, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0.0\n",
        "        with torch.no_grad():\n",
        "            for batch_i, batch in enumerate(test_loader):\n",
        "                if batch_i >= max_batches_per_epoch_val:\n",
        "                    break\n",
        "\n",
        "                inputs = batch.to(device)\n",
        "                targets = inputs.clone()\n",
        "                logits = model(inputs)\n",
        "                loss = loss_func(logits, targets)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "        train_loss /= max_batches_per_epoch_train\n",
        "        val_loss /= max_batches_per_epoch_val\n",
        "\n",
        "        if scheduler:\n",
        "            scheduler.step(val_loss)\n",
        "\n",
        "        print(f'Epoch {epoch+1}: Train Loss={train_loss:.4f}, Val Loss={val_loss:.4f}')\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_model = model.state_dict()\n",
        "            no_improvement = 0\n",
        "        else:\n",
        "            no_improvement += 1\n",
        "\n",
        "        if no_improvement >= early_stopping_patience:\n",
        "            print(\"Early stopping triggered\")\n",
        "            break\n",
        "\n",
        "    model.load_state_dict(best_model)\n",
        "    return best_loss, model"
      ],
      "metadata": {
        "id": "Jhn2WbSt8opM"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Обучение модели\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Используется устройство: {device}\")\n",
        "\n",
        "def lr_scheduler(optimizer):\n",
        "    return torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "        optimizer,\n",
        "        T_0=10,\n",
        "        T_mult=2,\n",
        "        eta_min=1e-6\n",
        "    )\n",
        "\n",
        "(best_val_loss, best_torch_transf_model) = train_eval_loop(\n",
        "    torch_transf_model,\n",
        "    train_dataset,\n",
        "    test_dataset,\n",
        "    lm_cross_entropy,\n",
        "    lr=1e-4,\n",
        "    epoch_n=500,\n",
        "    batch_size=128,\n",
        "    device=device,\n",
        "    early_stopping_patience=10,\n",
        "    max_batches_per_epoch_train=500,\n",
        "    max_batches_per_epoch_val=200,\n",
        "    lr_scheduler_ctor=lr_scheduler\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Op8Y5lLv8zn0",
        "outputId": "3f75d9d8-8360-41c3-c5c0-86dc06f6db75"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Используется устройство: cuda\n",
            "Epoch 1: Train Loss=0.5811, Val Loss=0.5968\n",
            "Epoch 2: Train Loss=0.5504, Val Loss=0.5859\n",
            "Epoch 3: Train Loss=0.5433, Val Loss=0.5777\n",
            "Epoch 4: Train Loss=0.5362, Val Loss=0.5709\n",
            "Epoch 5: Train Loss=0.5311, Val Loss=0.5649\n",
            "Epoch 6: Train Loss=0.5244, Val Loss=0.5576\n",
            "Epoch 7: Train Loss=0.5175, Val Loss=0.5511\n",
            "Epoch 8: Train Loss=0.5109, Val Loss=0.5433\n",
            "Epoch 9: Train Loss=0.5045, Val Loss=0.5380\n",
            "Epoch 10: Train Loss=0.4990, Val Loss=0.5334\n",
            "Epoch 11: Train Loss=0.4935, Val Loss=0.5286\n",
            "Epoch 12: Train Loss=0.4882, Val Loss=0.5239\n",
            "Epoch 13: Train Loss=0.4841, Val Loss=0.5200\n",
            "Epoch 14: Train Loss=0.4793, Val Loss=0.5161\n",
            "Epoch 15: Train Loss=0.4750, Val Loss=0.5112\n",
            "Epoch 16: Train Loss=0.4702, Val Loss=0.5072\n",
            "Epoch 17: Train Loss=0.4663, Val Loss=0.5038\n",
            "Epoch 18: Train Loss=0.4617, Val Loss=0.5003\n",
            "Epoch 19: Train Loss=0.4576, Val Loss=0.4964\n",
            "Epoch 20: Train Loss=0.4534, Val Loss=0.4925\n",
            "Epoch 21: Train Loss=0.4491, Val Loss=0.4897\n",
            "Epoch 22: Train Loss=0.4454, Val Loss=0.4862\n",
            "Epoch 23: Train Loss=0.4409, Val Loss=0.4835\n",
            "Epoch 24: Train Loss=0.4366, Val Loss=0.4806\n",
            "Epoch 25: Train Loss=0.4334, Val Loss=0.4780\n",
            "Epoch 26: Train Loss=0.4293, Val Loss=0.4754\n",
            "Epoch 27: Train Loss=0.4257, Val Loss=0.4723\n",
            "Epoch 28: Train Loss=0.4218, Val Loss=0.4697\n",
            "Epoch 29: Train Loss=0.4185, Val Loss=0.4671\n",
            "Epoch 30: Train Loss=0.4148, Val Loss=0.4650\n",
            "Epoch 31: Train Loss=0.4108, Val Loss=0.4623\n",
            "Epoch 32: Train Loss=0.4064, Val Loss=0.4601\n",
            "Epoch 33: Train Loss=0.4033, Val Loss=0.4577\n",
            "Epoch 34: Train Loss=0.3997, Val Loss=0.4556\n",
            "Epoch 35: Train Loss=0.3964, Val Loss=0.4541\n",
            "Epoch 36: Train Loss=0.3931, Val Loss=0.4519\n",
            "Epoch 37: Train Loss=0.3896, Val Loss=0.4502\n",
            "Epoch 38: Train Loss=0.3858, Val Loss=0.4482\n",
            "Epoch 39: Train Loss=0.3825, Val Loss=0.4465\n",
            "Epoch 40: Train Loss=0.3793, Val Loss=0.4454\n",
            "Epoch 41: Train Loss=0.3762, Val Loss=0.4437\n",
            "Epoch 42: Train Loss=0.3724, Val Loss=0.4417\n",
            "Epoch 43: Train Loss=0.3696, Val Loss=0.4412\n",
            "Epoch 44: Train Loss=0.3666, Val Loss=0.4395\n",
            "Epoch 45: Train Loss=0.3632, Val Loss=0.4383\n",
            "Epoch 46: Train Loss=0.3608, Val Loss=0.4375\n",
            "Epoch 47: Train Loss=0.3574, Val Loss=0.4368\n",
            "Epoch 48: Train Loss=0.3543, Val Loss=0.4359\n",
            "Epoch 49: Train Loss=0.3509, Val Loss=0.4350\n",
            "Epoch 50: Train Loss=0.3489, Val Loss=0.4341\n",
            "Epoch 51: Train Loss=0.3455, Val Loss=0.4340\n",
            "Epoch 52: Train Loss=0.3426, Val Loss=0.4331\n",
            "Epoch 53: Train Loss=0.3402, Val Loss=0.4326\n",
            "Epoch 54: Train Loss=0.3380, Val Loss=0.4320\n",
            "Epoch 55: Train Loss=0.3345, Val Loss=0.4320\n",
            "Epoch 56: Train Loss=0.3316, Val Loss=0.4317\n",
            "Epoch 57: Train Loss=0.3292, Val Loss=0.4312\n",
            "Epoch 58: Train Loss=0.3266, Val Loss=0.4309\n",
            "Epoch 59: Train Loss=0.3245, Val Loss=0.4303\n",
            "Epoch 60: Train Loss=0.3211, Val Loss=0.4305\n",
            "Epoch 61: Train Loss=0.3190, Val Loss=0.4306\n",
            "Epoch 62: Train Loss=0.3165, Val Loss=0.4302\n",
            "Epoch 63: Train Loss=0.3139, Val Loss=0.4300\n",
            "Epoch 64: Train Loss=0.3114, Val Loss=0.4306\n",
            "Epoch 65: Train Loss=0.3090, Val Loss=0.4303\n",
            "Epoch 66: Train Loss=0.3065, Val Loss=0.4307\n",
            "Epoch 67: Train Loss=0.3045, Val Loss=0.4301\n",
            "Epoch 68: Train Loss=0.3018, Val Loss=0.4308\n",
            "Epoch 69: Train Loss=0.2995, Val Loss=0.4308\n",
            "Epoch 70: Train Loss=0.2979, Val Loss=0.4306\n",
            "Epoch 71: Train Loss=0.2955, Val Loss=0.4311\n",
            "Epoch 72: Train Loss=0.2929, Val Loss=0.4313\n",
            "Epoch 73: Train Loss=0.2904, Val Loss=0.4319\n",
            "Early stopping triggered\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Сохранение и загрузка лучшей модели\n",
        "torch.save(best_torch_transf_model.state_dict(), 'war_and_peace_torch_transf_best.pth')\n",
        "print(\"Модель сохранена\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l1kQZIFM83ne",
        "outputId": "9223dc99-2e81-49af-8aa5-bb56cf88551e"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Модель сохранена\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Загрузка сохраненной модели\n",
        "torch_transf_model.load_state_dict(torch.load('war_and_peace_torch_transf_best.pth'))"
      ],
      "metadata": {
        "id": "HJbqVmDa_0SO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c7a6bb8f-1806-4b6b-aecc-34a445cb6155"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 7. Генерация текста"
      ],
      "metadata": {
        "id": "UhJE31VH_5zL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Класс для генерации текста\n",
        "class GreedyGenerator:\n",
        "    \"\"\"Жадный генератор текста с кэшированием\"\"\"\n",
        "    def __init__(self, model, tokenizer):\n",
        "        self.model = model\n",
        "        self.tokenizer = tokenizer\n",
        "\n",
        "    def __call__(self, seed_text, max_len=50):\n",
        "        self.model.eval()\n",
        "        tokens = self.tokenizer.encode([seed_text], bos=True)[0]\n",
        "        device = self.model.device\n",
        "        tokens_tensor = torch.tensor(tokens).unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for _ in range(max_len):\n",
        "                # Используем только последние CHUNK_LENGTH токенов\n",
        "                input_tokens = tokens_tensor[:, -CHUNK_LENGTH:]\n",
        "\n",
        "                logits = self.model(input_tokens)\n",
        "                next_token = torch.argmax(logits[0, -1, :])\n",
        "\n",
        "                # Проверяем EOS (конец последовательности)\n",
        "                if next_token.item() == 3:  # EOS token\n",
        "                    break\n",
        "\n",
        "                tokens.append(next_token.item())\n",
        "                tokens_tensor = torch.tensor(tokens).unsqueeze(0).to(device)\n",
        "\n",
        "        return self.tokenizer.decode(tokens)[0]"
      ],
      "metadata": {
        "id": "h1vcKJUF_6cg"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Генерация текста\n",
        "greedy_generator = GreedyGenerator(torch_transf_model, tokenizer)\n",
        "\n",
        "print(\"\\nГенерация текста:\")\n",
        "print(greedy_generator('сказала княжна, оглядывая '))\n",
        "print(greedy_generator('смеялась княжна, оглядывая '))\n",
        "print(greedy_generator('Наполеон хочет '))"
      ],
      "metadata": {
        "id": "pj1soqmr_7nw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cbec0b7-31b8-4b36-c18a-48482a13cc33"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Генерация текста:\n",
            "<BOS> сказала княжна, оглядывая на Анну Павловна.\n",
            "<BOS> смеялась княжна, оглядывая на него и на него глазами, ногу, что он не мог понять, что он был в том, что он был в том, что он был в душе.\n",
            "<BOS> Наполеон хочет еще не мог понять, как будто он был в том, что он был в том, что он был в Петербурге, и что он был в душе в Петербурге, и что он был в этом случае должно было бы мог бы мог бы мог бы мог бы мог\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DmfmjJ5aBE3V"
      },
      "execution_count": 24,
      "outputs": []
    }
  ]
}